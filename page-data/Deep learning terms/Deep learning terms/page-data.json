{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/Deep learning terms/Deep learning terms/",
    "result": {"data":{"cur":{"id":"f13399e6-5a6e-51a0-bc73-e8ddd1a42087","html":"<p><strong>안녕하세요. 오늘은 딥 러닝의 기초적인 용어들을 정리해보겠습니다. 기초 용어라고 해도 제가 배운 내용을 토대로 정리하는 거라 빠진 부분이나 틀린 부분이 많을 수 있습니다! 또한 주로 컴퓨터 비전 분야에서 많이 쓰이는 용어들을 주로 정리 했습니다!</strong></p>\n<h3 id=\"1-data\" style=\"position:relative;\"><a href=\"#1-data\" aria-label=\"1 data permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Data</h3>\n<p>모델을 학습시키는 데이터. 일반적으로 모델에 들어가기 전 전처리를 필요로 한다.</p>\n<h3 id=\"2-model\" style=\"position:relative;\"><a href=\"#2-model\" aria-label=\"2 model permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Model</h3>\n<p>다양한 Layer 층으로 구성된 네트워크이다. 학습을 할 수 있는 파라미터들이 들어있다.</p>\n<h3 id=\"3-convolution-layer\" style=\"position:relative;\"><a href=\"#3-convolution-layer\" aria-label=\"3 convolution layer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Convolution Layer</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 652px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 84.44444444444446%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsTAAALEwEAmpwYAAADUUlEQVQ4y21U/W/iRhD1//9TlUS6qDmppARw+DABYoNtME4wBJxKx9WgHknAEL5SIOT4uGCDva9ac6CSdqUnz87Ovp3ZfWNGluXFer1eA7Bc17UB2IQQD9T+iJ1/OBzatXr9P/EMx3G2pmnYbDagw3Vd70sI8fBx7NZ7vR6SqRRapnkQzwRDISudyaB0d0dWqxVlIK7rkm2Mx3iA3Vq73SbxeJwo+Tz50zD28czFxYXFCwJESSTZbBaO4+xP/PfJO+wy7PZ6iMZikCQJMY6D2W57foa9vLRSPI+UkCbhaAxfqlWsbfuAdDs5LPm520UkGoUgCAiGQiiWSqjVamD84ajF3j8gxovEFwgiWyih1X/BygUWa4LW8BmT5RAEzvaAn8Sd5w64eBw5RcFFIACtWMTvfj8YThCtyNMcsWqbsFwCmZwCszcAzYPCqNVxnUlhNOtj6U6xWL95hIP+ENcpAWJGgu/8HEo+j1+OjsBEr9PWVWOCwOOC+AQV6YwIsz/0NLJcu6g9tuAPx1G4L8LCHFP7BQtMYHT+QEQIQivfIsSyKGgajk9OtoTxxyliT3MSSuehyiKmr6/7q2s+NcELaS8DOt43C6wwx8PAwLl0gmydQ1aVod7cbAm5FG9FakOwT0vCKmVIOQXPL2PYBFg5BA9mExwfgVTgYWOJH5s5Vpjhr95XcKkYFCXv3aGu6zg6PgYTvmQtQdMRN5cknCuiVNTQH01AW4cSzn4sIGYFFG4176ln9gQOLHR7XVxdJZBXVQSCQVQqFfzm84FJpFIWn7yCVKkSP5+DWryDOfgbFgHm1gZUlS+vc5S/VvCO71g7W0mNRiOvU/aEuo5fz87ANJtNS5JlyGKGRCJh3BYKmEwme+lNv88wnS+oaPaSoYM2ANUs3Rv8meHZ589g6E9hMBhAlGVyGYmA9vV4PN5vrNfrYFkW5XL5f3vcMAzvlekdfjo9BaOq6vttoeB+qVadRCLh5FXVGY/HtFLHdV1nm4zjbJyNZ1PYtu2oNzeOqqqOoiieXSqVnE+npw6TEUUkk8mt+judw5I/ZLOzabm0M3ie92Kp/1ujsS35W6NRrFar94QQHYDeMk397e3Ns6nvI6jfdV3dNE3dMAxvvkOM4/R/AArguxPBjimYAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Untitled\"\n        title=\"Untitled\"\n        src=\"/static/c976e380ff6d694a0ecaef825f007043/dba9a/Untitled.png\"\n        srcset=\"/static/c976e380ff6d694a0ecaef825f007043/e9ff0/Untitled.png 180w,\n/static/c976e380ff6d694a0ecaef825f007043/f21e7/Untitled.png 360w,\n/static/c976e380ff6d694a0ecaef825f007043/dba9a/Untitled.png 652w\"\n        sizes=\"(max-width: 652px) 100vw, 652px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p><img src=\"Untitled1.png\" alt=\"Untitled1\"></p>\n<p><strong>합성 곱 계층</strong>이라고 불리며 입력 값에 대해서 Filter를 합성 곱을 진행해서 Feature Map을 뽑아주는 계층이다. 뒤에서 나오겠지만 padding이라는 과정을 거치지 않으면 입력에 비해 출력 map은 크기가 줄어든다. 이렇게 나온 출력 Feature Map은 특징 맵이라고 불리며 입력 이미지에서 각 필터에 해당하는 특징을 뽑아낸 것이라고 생각하면 된다. (이 부분이 처음에는 직관적으로 이해하기 어려웠는데 아래 그림을 보고 조금은 도움이 되었다.)</p>\n<blockquote>\n<p>(+) 아래 그림에서 좌측의 동그라미가 각 입력 이미지들이고 작은 이미지가 필터이다. 그렇게 특징을 뽑아내면 세번째 그림같이 특정 response가 나타난다. 이런 식으로 특징을 뽑는다고 이해하면 조금은 편해질 것 같다.</p>\n</blockquote>\n<p><img src=\"Untitled2.png\" alt=\"Untitled2\"></p>\n<h3 id=\"4-parameter--hyper-parameter\" style=\"position:relative;\"><a href=\"#4-parameter--hyper-parameter\" aria-label=\"4 parameter  hyper parameter permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Parameter / Hyper Parameter</h3>\n<p><strong>Parameter</strong>는 매개변수라는 뜻으로 모델 내부에서 데이터로부터 결정되는 변수입니다.</p>\n<p><strong>Hyper Parameter</strong>는 모델링할 때 사람이 직접 정해주어야하는 변수입니다.</p>\n<h3 id=\"5-channel--kernel\" style=\"position:relative;\"><a href=\"#5-channel--kernel\" aria-label=\"5 channel  kernel permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. Channel / Kernel</h3>\n<p><img src=\"Untitled3.png\" alt=\"Untitled3\"></p>\n<p><strong>채널</strong>은 각 계층의 이미지에서 특징의 개수라고 생각하면 편합니다. 일반적으로 입력 이미지는 RGB 3개의 채널을 가졌고 convolution을 거듭할 수록 늘어납니다. 각 계층의 커널의 개수가 채널의 개수와 동일한데, 그 계층의 출력 feature map의 개수 또한 동일하므로 특징의 개수라고 이해할 수 있습니다.</p>\n<p><strong>커널</strong>은 앞선 설명에서는 filter라고 불렀던 것과 같습니다. 사실 filter보다 많이 쓰이는 용어가 커널이지만 앞에선 설명을 위해 filter라는 용어를 썼고 이제부터는 kernel이라고 부르겠습니다. 일반적으로 정사각 행렬로 이루어졌고 특징을 찾아내기 위한 파라미터이고 학습을 거듭할 수록 더욱 좋은 특징을 찾아내도록 학습됩니다.</p>\n<h3 id=\"6-stride--padding\" style=\"position:relative;\"><a href=\"#6-stride--padding\" aria-label=\"6 stride  padding permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>6. Stride / Padding</h3>\n<p><img src=\"Untitled4.png\" alt=\"Untitled4\"></p>\n<p><img src=\"Untitled5.png\" alt=\"Untitled5\"></p>\n<p><strong>Stride</strong>는 보폭이라는 뜻으로, kernel이 몇 칸씩 뛰어 넘으며 합성 곱을 수행하는지 결정하는 하이퍼 파라미터입니다.</p>\n<p><strong>Padding</strong>은 합성 곱을 진행할 때 입력 이미지의 가장자리는 kernel이 한번 밖에 거치지 않기 때문에 영향력이 무시될 수 있습니다. 이를 방지하기 위해 진행하는 padding은 가장자리에 상하좌우에 특정 값으로 채운 몇 줄을 추가해서 입력 이미지의 크기를 키워주는 것입니다. 주로 <strong>zero padding</strong>을 쓰며 이는 0으로 채워줍니다.</p>\n<h3 id=\"7-pooling\" style=\"position:relative;\"><a href=\"#7-pooling\" aria-label=\"7 pooling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>7. Pooling</h3>\n<p><img src=\"Untitled6.png\" alt=\"Untitled6\"></p>\n<p><img src=\"Untitled7.png\" alt=\"Untitled7\"></p>\n<p><strong>Pooling</strong>은 여러 pixel의 값을 하나의 pixel로 줄여주는 것으로 영상의 크기를 줄이고 정보를 종합하고 싶을 때 사용합니다. Max pooling, Average pooling 등 여러 종류가 있으며 max pooling은 해당 pixel중 가장 큰 값을, average pooling은 평균을 채택합니다.</p>\n<h3 id=\"8-receptive-field\" style=\"position:relative;\"><a href=\"#8-receptive-field\" aria-label=\"8 receptive field permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>8. Receptive Field</h3>\n<p><img src=\"Untitled8.png\" alt=\"Untitled8\"></p>\n<p><strong>Receptive Field</strong>는 kernel로 입력 영상에 대해 연산을 수행할 때 해당 연산의 결과에서 한 pixel이 얼만큼의 pixel 정보들을 내포하는 지를 나타냅니다. 예를 들어보자면 5x5 kernel을 한번 적용한 결과 map의 한 pixel은 입력 영상의 5x5 영역의 정보를 포함합니다. 그렇다면 3x3 kernel을 두번 연속으로 적용한다면 결과는 어떻게 될까요? 이 두가지 예의 receptive field는 서로 같습니다. 3x3을 수행하고 한번 더 3x3을 수행한다면 3x3의 receptive field를 가지고 있는 첫 번째 feature map에서 3x3을 한번 더 진행한 것이므로 5x5의 같은 receptive field를 가집니다.</p>\n<blockquote>\n<p>큰 receptive field는 local information과 contextual information이 중요한 컴퓨터 비전 분야에서는 정확도 면에서 좋은 결과를 뽑아내는 데 도움이 됩니다.</p>\n</blockquote>\n<h3 id=\"9-activation-function\" style=\"position:relative;\"><a href=\"#9-activation-function\" aria-label=\"9 activation function permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>9. Activation Function</h3>\n<p><img src=\"Untitled9.png\" alt=\"Untitled9\"></p>\n<p>활성 함수라는 뜻으로 입력 값을 신호로 본다면 이 신호가 활성화되는지 확인하는, 즉 필요한 값을 솎아내는 역할을 합니다. 활성 함수에는 굉장히 많은 종류가 있습니다. 대표적으로 Sigmoid, ReLU 등이 있고 이 활성 함수는 모델의 비선형성을 증가 시켜주는 역할도 있습니다.</p>\n<h3 id=\"10-마무리\" style=\"position:relative;\"><a href=\"#10-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"10 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>10. 마무리</h3>\n<p>여기까지 기초 용어들을 정리해봤습니다. 사실 아직 정리하지 못한 용어가 산더미입니다.😢 Batch, back propagation 등등 아주 많아요.. 나머지 용어들은 기초 용어 정리 2에서 더 정리해보겠습니다.</p>\n<p>읽어주셔서 감사합니다!</p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#1-data\">1. Data</a></li>\n<li><a href=\"#2-model\">2. Model</a></li>\n<li><a href=\"#3-convolution-layer\">3. Convolution Layer</a></li>\n<li><a href=\"#4-parameter--hyper-parameter\">4. Parameter / Hyper Parameter</a></li>\n<li><a href=\"#5-channel--kernel\">5. Channel / Kernel</a></li>\n<li><a href=\"#6-stride--padding\">6. Stride / Padding</a></li>\n<li><a href=\"#7-pooling\">7. Pooling</a></li>\n<li><a href=\"#8-receptive-field\">8. Receptive Field</a></li>\n<li><a href=\"#9-activation-function\">9. Activation Function</a></li>\n<li><a href=\"#10-%EB%A7%88%EB%AC%B4%EB%A6%AC\">10. 마무리</a></li>\n</ul>\n</div>","excerpt":"안녕하세요. 오늘은 딥 러닝의 기초적인 용어들을 정리해보겠습니다. 기초 용어라고 해도 제가 배운 내용을 토대로 정리하는 거라 빠진 부분이나 틀린 부분이 많을 수 있습니다! 또한 주로 컴퓨터 비전 분야에서 많이 쓰이는 용어들을 주로 정리 했습니다! 1. Data 모델을 학습시키는 데이터. 일반적으로 모델에 들어가기 전 전처리를 필요로 한다. 2. Model 다양한 Layer 층으로 구성된 네트워크이다. 학습을 할 수 있는 파라미터들이 들어있다. 3. Convolution Layer  Untitled1 합성 곱 계층이라고 불리며 입력 값에 대해서 Filter를 합성 곱을 진행해서 Feature Map을 뽑아주는 계층이다. 뒤에서 나오겠지만 padding이라는 과정을 거치지 않으면 입력에 비해 출력 map은 크기가 줄어든다. 이렇게 나온 출력 Feature Map은 특징 맵이라고 불리며 입력 이미지에서 각 필터에 해당하는 특징을 뽑아낸 것이라고 생각하면 된다. (이 부분이 처음에는 직관…","frontmatter":{"date":"January 18, 2022","title":"딥러닝 기초 용어 정리","categories":"Basic","author":"Yon_ninii","emoji":"🎼"},"fields":{"slug":"/Deep learning terms/Deep learning terms/"}},"next":{"id":"83174d6b-53fc-5e6e-9830-c250541485fe","html":"<h2 id=\"새롭게-만들게-된-ai와-컴퓨터-비전에-대해-공부한-내용을-정리하는-블로그입니다\" style=\"position:relative;\"><a href=\"#%EC%83%88%EB%A1%AD%EA%B2%8C-%EB%A7%8C%EB%93%A4%EA%B2%8C-%EB%90%9C-ai%EC%99%80-%EC%BB%B4%ED%93%A8%ED%84%B0-%EB%B9%84%EC%A0%84%EC%97%90-%EB%8C%80%ED%95%B4-%EA%B3%B5%EB%B6%80%ED%95%9C-%EB%82%B4%EC%9A%A9%EC%9D%84-%EC%A0%95%EB%A6%AC%ED%95%98%EB%8A%94-%EB%B8%94%EB%A1%9C%EA%B7%B8%EC%9E%85%EB%8B%88%EB%8B%A4\" aria-label=\"새롭게 만들게 된 ai와 컴퓨터 비전에 대해 공부한 내용을 정리하는 블로그입니다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>새롭게 만들게 된 A.I와 컴퓨터 비전에 대해 공부한 내용을 정리하는 블로그입니다.</h2>\n<p>첫 포스팅이라 뭔가 긴장이 됩니다. 그래도 열심히 가꿔볼 생각이니 잘 봐주시면 감사하겠습니다.\n또한 그저 학부생 수준의 공부이니 전문적인 내용은 많이 틀릴 수 있습니다. 부정적인 피드백들도 환영입니다!\n프로필에도 있지만 제 소개를 간단히 해보자면 인하대학교 정보통신공학과에 재학중이고 현재 학교에 있는 A.I 컴퓨터 비전 연구실에서 학부 연구생으로 공부중입니다. 여러 비전관련 논문을 읽으면서 어디에 정리를 하고 싶어서 블로그를 시작했습니다.\n주로 논문 리뷰를 할 예정이고 따로 시간이 된다면 PyTorch와 수학적인 강의 리뷰도 다뤄보겠습니다. 잘 부탁드립니다!</p>\n<p>(+) 추가로 블로그 제작은 <a href=\"https://www.zoomkoding.com/gatsby-github-blog/\">줌코딩님</a>의 게시글을 참고해서 만들었습니다.</p>","frontmatter":{"date":"January 14, 2022","title":"블로그 오픈했습니다!","categories":"블로그","author":"Yon_ninii","emoji":"😋"},"fields":{"slug":"/Introduction/"}},"prev":null,"site":{"siteMetadata":{"siteUrl":"https://yon-ninii.github.io","comments":{"utterances":{"repo":""}}}}},"pageContext":{"slug":"/Deep learning terms/Deep learning terms/","nextSlug":"/Introduction/","prevSlug":""}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}